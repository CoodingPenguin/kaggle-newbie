# ëˆˆëˆ„ë‚œë‚˜ NunnuNanna ìºê¸€ ìŠ¤í„°ë””

ë°ì´í„°ë¶„ì„ ê¸°ìˆ  ìŠ¤í„°ë”” ê·¸ë£¹ ëˆˆëˆ„ë‚œë‚˜ NunnuNannaì˜ 14ì£¼ì°¨ ìºê¸€ ìŠ¤í„°ë”” ê³¼ì œìž…ë‹ˆë‹¤.

ìºê¸€ ì½”ë¦¬ì•„ ë¸”ë¡œê·¸ì— ì˜¬ë¼ì˜¨ [ì´ìœ í•œ ë‹˜ì˜ ìºê¸€ ì»¤ë„ ì»¤ë¦¬í˜ëŸ¼](https://kaggle-kr.tistory.com/32)ì„ ë”°ë¼ ë°ì´í„° ë¶„ì„ ê¸°ìˆ ì„ ê³µë¶€í•©ë‹ˆë‹¤.

## âœ… ì²´í¬í‘œ

|     | w1  | w2  | w3  | w4  | w5  | w6  | w7  | w8  | w9  | w10 | w11 | w12 | w13 | w14 |
| --- | :-: | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1   |  âœ”  |     |     |     |     |     |     |     |     |     |     |     |     |     |
| 2   |  âœ”  |     |     |     |     |     |     |     |     |     |     |     |     |     |
| 3   |  âœ”  |     |     |     |     |     |     |     |     |     |     |     |     |     |

## âœ’ ê³µë¶€ ë°©ë²•

1. í•„ì‚¬ì ìœ¼ë¡œ í•„ì‚¬í•œë‹¤
2. ì»¤ë„ì˜ Aë¶€í„° Zê¹Œì§€ ë‹¤ ë˜‘ê°™ì´ ë”°ë¼ ì ëŠ”ë‹¤.
3. ë˜‘ê°™ì´ 3ë²ˆ ì ê³  ë‹¤ìŒ ì»¤ë„ë¡œ ë„˜ì–´ê°„ë‹¤.

## ðŸ“„ ì»¤ë¦¬í˜ëŸ¼

### Binary Classification: Tabular Data

### [1st level. Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)

- [x] [íƒ€ì´íƒ€ë‹‰ íŠœí† ë¦¬ì–¼ 1 - exploratory data analysis, visualization, machine learning](https://kaggle-kr.tistory.com/17?category=868316)
- [ ] [eda to prediction(dietanic)](https://www.kaggle.com/ash316/eda-to-prediction-dietanic)
- [ ] [titanic top 4% with ensemble modeling](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling)
- [ ] [introduction to ensembling/stacking in python](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python)

### [2nd level. Porto Seguroâ€™s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)

- [ ] [data preparation & exploration](https://www.kaggle.com/bertcarremans/data-preparation-exploration)
- [ ] [interactive porto insights - a plot.ly tutorial](https://www.kaggle.com/arthurtok/interactive-porto-insights-a-plot-ly-tutorial)
- [ ] [xgboost cv (lb .284)](https://www.kaggle.com/aharless/xgboost-cv-lb-284)
- [ ] [porto seguro exploratory analysis and prediction](https://www.kaggle.com/gpreda/porto-seguro-exploratory-analysis-and-prediction)

### [3rd level. Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk)

- [ ] [introduction: home credit default risk competition](https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction)
- [ ] [introduction to manual feature engineering](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering)
- [ ] [stacking test-sklearn, xgboost, catboost, lightgbm](https://www.kaggle.com/eliotbarr/stacking-test-sklearn-xgboost-catboost-lightgbm)
- [ ] [lightgbm 7th place solution](https://www.kaggle.com/jsaguiar/lightgbm-7th-place-solution)

### Multi-class Classification: Tabular Data

### [1st level. Costa-rican competition](https://www.kaggle.com/c/cost)

- [ ] [A Complete Introduction and Walkthrough](https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough)
- [ ] [3250feats->532 feats using shap[LB: 0.436]](https://www.kaggle.com/youhanlee/3250feats-532-feats-using-shap-lb-0-436)
- [ ] [XGBoost](https://www.kaggle.com/skooch/xgboost)

### Binary Classification: Image Classification

### [1st level. Statoil/C-CORE Iceberg Classifier Challenge](https://www.kaggle.com/c/statoil-iceberg-classifier-challenge)

- [ ] [keras model for beginners (0.210 on lb)+eda+r&d](https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d)
- [ ] [transfer learning with vgg-16 cnn+aug lb 0.1712](https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712)
- [ ] [submarineering.even better public score until now.](https://www.kaggle.com/submarineering/submarineering-even-better-public-score-until-now)
- [ ] [keras+tf lb 0.18](https://www.kaggle.com/wvadim/keras-tf-lb-0-18)

### Multi-class Classification: Image Classification

### [1st level. Fruits 360](https://www.kaggle.com/uciml/mush)

- [ ] [Fruits-360 - Transfer Learning using Keras](https://www.kaggle.com/amadeus1996/fruits-360-transfer-learning-using-keras)

### [2nd level. Fruits 360](https://www.kaggle.com/zalando-research/fashionmnist)

- [ ] [How Autoencoders Work: Intro and UseCases](https://www.kaggle.com/shivamb/how-autoencoders-work-intro-and-usecases)
- [ ] [CNN with Keras](https://www.kaggle.com/bugraokcu/cnn-with-keras)

### Regression: Tabular data

### [1st level. New York City Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration)

- [ ] [dynamics of new york city - animation](https://www.kaggle.com/drgilermo/dynamics-of-new-york-city-animation)
- [ ] [eda + baseline model](https://www.kaggle.com/aiswaryaramachandran/eda-baseline-model-0-40-rmse)
- [ ] [beat the benchmark!](https://www.kaggle.com/danijelk/beat-the-benchmark)

### [2nd level. Zillow Prize: Zillowâ€™s Home Value Prediction (Zestimate)](https://www.kaggle.com/c/zillow-prize-1)

- [ ] [simple exploration notebook - zillow prize](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize)
- [ ] [simple xgboost starter (~0.0655)](https://www.kaggle.com/anokas/simple-xgboost-starter-0-0655)
- [ ] [zillow eda on missing values & multicollinearity](https://www.kaggle.com/viveksrinivasan/zillow-eda-on-missing-values-multicollinearity)
- [ ] [xgboost, lightgbm, and ols and nn](https://www.kaggle.com/aharless/xgboost-lightgbm-and-ols-and-nn)

### Object segmentation: Deep learning

### [1st level. 2018 Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2018)

- [ ] [teaching notebook for total imaging newbies](https://www.kaggle.com/stkbailey/teaching-notebook-for-total-imaging-newbies)
- [ ] [keras u-net starter - lb 0.277](https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277)
- [ ] [nuclei overview to submission](https://www.kaggle.com/kmader/nuclei-overview-to-submission)

### Natural language processing: classification, regression

### [1st level. Spooky Author Identification](https://www.kaggle.com/c/spooky-author-identification)

- [ ] [spooky nlp and topic modelling tutorial](https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial)
- [ ] [approaching (almost) any nlp problem on kaggle](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle)
- [ ] [simple feature engg notebook - spooky author](https://www.kaggle.com/sudalairajkumar/simple-feature-engg-notebook-spooky-author)

### [2nd level. Mercari Price Suggestion Challenge](https://www.kaggle.com/c/mercari-price-suggestion-challenge)

- [ ] [mercari interactive eda + topic modelling](https://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling)
- [ ] [a simple nn solution with keras (~0.48611 pl)](https://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl)
- [ ] [ridge (lb 0.41943)](https://www.kaggle.com/rumbok/ridge-lb-0-41944)
- [ ] [LGB and FM [18th Place - 0.40604]](https://www.kaggle.com/peterhurford/lgb-and-fm-18th-place-0-40604)

### [3rd level. Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

- [ ] [[For Beginners] Tackling Toxic Using Keras](https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras)
- [ ] [stop the s@#\$ - toxic comments eda](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)
- [ ] [logistic regression with words and char n-grams](https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams)
- [ ] [classifying multi-label comments (0.9741 lb)](https://www.kaggle.com/rhodiumbeng/classifying-multi-label-comments-0-9741-lb)

### Other dataset : anomaly detection, visualization

### [1st level. Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)

- [ ] [in depth skewed data classif. (93% recall acc now)](https://www.kaggle.com/joparga3/in-depth-skewed-data-classif-93-recall-acc-now)
- [ ] [anomaly detection - credit card fraud analysis](https://www.kaggle.com/pavansanagapati/anomaly-detection-credit-card-fraud-analysis)
- [ ] [semi-supervised anomaly detection survey](https://www.kaggle.com/matheusfacure/semi-supervised-anomaly-detection-survey)

### [2nd level. Kaggle Machine Learning & Data Science Survey 2017](https://www.kaggle.com/kaggle/kaggle-survey-2017)

- [ ] [novice to grandmaster](https://www.kaggle.com/ash316/novice-to-grandmaster)
- [ ] [what do kagglers say about data science ?](https://www.kaggle.com/mhajabri/what-do-kagglers-say-about-data-science)
- [ ] [plotly tutorial - 1](https://www.kaggle.com/hakkisimsek/plotly-tutorial-1)
